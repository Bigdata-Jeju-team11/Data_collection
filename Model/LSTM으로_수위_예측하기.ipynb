{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM으로 수위 예측하기.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKDD0bu0sGG_",
        "colab_type": "text"
      },
      "source": [
        "- LSTM은 RNN(Recurrent Neural Network) 알고리즘의 특별한 한 종류입니다.\n",
        "- RNN은 글, 유전자, 손글씨, 음성 신호, 주가 등 배열(sequence 또는 시계열 데이터)의 형태를 갖는 데이터에서 패턴을 인식하는 인공 신경망입니다.\n",
        "- LSTM은 기존 RNN을 개선한 모델로 긴 의존 기간(long-term dependency)을 필요로 하는 데이터를 학습하는데 효과적인 모델입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djV81Wv-pFWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!df -h # 하드디스크 확인"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsSfQh60pMx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /proc/meminfo # 메모리 체크"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UDUgJPSpiCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /proc/cpuinfo # cpu 정보"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC8qpRXyp4YR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ef10284-fe8e-44a8-e7a1-184144b7983f"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA7oDPnpq027",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "2b959465-dc62-4bb0-c2aa-1b34b86e453a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 파일 업로드 기능 실행 \n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-76e0e69b-e836-4759-a493-a733fe7f42cf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-76e0e69b-e836-4759-a493-a733fe7f42cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 교량_기준_임시_최종db.csv to 교량_기준_임시_최종db.csv\n",
            "User uploaded file \"교량_기준_임시_최종db.csv\" with length 672898034 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUetNrj8rb2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "outputId": "eaa148f2-d324-4d83-af1c-94bdceaf2254"
      },
      "source": [
        "df = pd.read_csv('/content/교량_기준_임시_최종db.csv')\n",
        "df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>bridge_name</th>\n",
              "      <th>address</th>\n",
              "      <th>etc_address</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>brid_height_origin</th>\n",
              "      <th>location_start</th>\n",
              "      <th>wl_station_code</th>\n",
              "      <th>rf_station_code</th>\n",
              "      <th>obs_date</th>\n",
              "      <th>WL</th>\n",
              "      <th>rainfall</th>\n",
              "      <th>bridge_height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>신원교</td>\n",
              "      <td>경기도</td>\n",
              "      <td>이천시</td>\n",
              "      <td>37.291282</td>\n",
              "      <td>127.509880</td>\n",
              "      <td>5.4</td>\n",
              "      <td>[37.291282, 127.50988000000001]</td>\n",
              "      <td>1007645</td>\n",
              "      <td>10074060</td>\n",
              "      <td>2010-02-25 12:00:00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>510.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>신원교</td>\n",
              "      <td>경기도</td>\n",
              "      <td>이천시</td>\n",
              "      <td>37.291282</td>\n",
              "      <td>127.509880</td>\n",
              "      <td>5.4</td>\n",
              "      <td>[37.291282, 127.50988000000001]</td>\n",
              "      <td>1007645</td>\n",
              "      <td>10074060</td>\n",
              "      <td>2010-02-25 13:00:00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>510.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>신원교</td>\n",
              "      <td>경기도</td>\n",
              "      <td>이천시</td>\n",
              "      <td>37.291282</td>\n",
              "      <td>127.509880</td>\n",
              "      <td>5.4</td>\n",
              "      <td>[37.291282, 127.50988000000001]</td>\n",
              "      <td>1007645</td>\n",
              "      <td>10074060</td>\n",
              "      <td>2010-02-25 14:00:00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>510.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>신원교</td>\n",
              "      <td>경기도</td>\n",
              "      <td>이천시</td>\n",
              "      <td>37.291282</td>\n",
              "      <td>127.509880</td>\n",
              "      <td>5.4</td>\n",
              "      <td>[37.291282, 127.50988000000001]</td>\n",
              "      <td>1007645</td>\n",
              "      <td>10074060</td>\n",
              "      <td>2010-02-25 15:00:00</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>510.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>신원교</td>\n",
              "      <td>경기도</td>\n",
              "      <td>이천시</td>\n",
              "      <td>37.291282</td>\n",
              "      <td>127.509880</td>\n",
              "      <td>5.4</td>\n",
              "      <td>[37.291282, 127.50988000000001]</td>\n",
              "      <td>1007645</td>\n",
              "      <td>10074060</td>\n",
              "      <td>2010-02-25 16:00:00</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>510.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097827</th>\n",
              "      <td>4097827</td>\n",
              "      <td>4381107</td>\n",
              "      <td>대곡교</td>\n",
              "      <td>서울특별시</td>\n",
              "      <td>강남구</td>\n",
              "      <td>37.468243</td>\n",
              "      <td>127.121565</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[37.468243, 127.12156499999999]</td>\n",
              "      <td>1018655</td>\n",
              "      <td>10184100</td>\n",
              "      <td>2017-06-26 17:00:00</td>\n",
              "      <td>184.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>483.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097828</th>\n",
              "      <td>4097828</td>\n",
              "      <td>4381108</td>\n",
              "      <td>대곡교</td>\n",
              "      <td>서울특별시</td>\n",
              "      <td>강남구</td>\n",
              "      <td>37.468243</td>\n",
              "      <td>127.121565</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[37.468243, 127.12156499999999]</td>\n",
              "      <td>1018655</td>\n",
              "      <td>10184100</td>\n",
              "      <td>2017-06-26 18:00:00</td>\n",
              "      <td>184.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>483.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097829</th>\n",
              "      <td>4097829</td>\n",
              "      <td>4381109</td>\n",
              "      <td>대곡교</td>\n",
              "      <td>서울특별시</td>\n",
              "      <td>강남구</td>\n",
              "      <td>37.468243</td>\n",
              "      <td>127.121565</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[37.468243, 127.12156499999999]</td>\n",
              "      <td>1018655</td>\n",
              "      <td>10184100</td>\n",
              "      <td>2017-06-26 19:00:00</td>\n",
              "      <td>185.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>483.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097830</th>\n",
              "      <td>4097830</td>\n",
              "      <td>4381110</td>\n",
              "      <td>대곡교</td>\n",
              "      <td>서울특별시</td>\n",
              "      <td>강남구</td>\n",
              "      <td>37.468243</td>\n",
              "      <td>127.121565</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[37.468243, 127.12156499999999]</td>\n",
              "      <td>1018655</td>\n",
              "      <td>10184100</td>\n",
              "      <td>2017-06-26 20:00:00</td>\n",
              "      <td>185.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>483.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097831</th>\n",
              "      <td>4097831</td>\n",
              "      <td>4381111</td>\n",
              "      <td>대곡교</td>\n",
              "      <td>서울특별시</td>\n",
              "      <td>강남구</td>\n",
              "      <td>37.468243</td>\n",
              "      <td>127.121565</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[37.468243, 127.12156499999999]</td>\n",
              "      <td>1018655</td>\n",
              "      <td>10184100</td>\n",
              "      <td>2017-06-26 21:00:00</td>\n",
              "      <td>185.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>483.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4097832 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0  Unnamed: 0.1 bridge_name  ...     WL rainfall  bridge_height\n",
              "0                 0             0         신원교  ...    3.0      0.0          510.0\n",
              "1                 1             1         신원교  ...    6.0      0.0          510.0\n",
              "2                 2             2         신원교  ...   10.0      0.0          510.0\n",
              "3                 3             3         신원교  ...   14.0      0.0          510.0\n",
              "4                 4             4         신원교  ...   18.0      0.0          510.0\n",
              "...             ...           ...         ...  ...    ...      ...            ...\n",
              "4097827     4097827       4381107         대곡교  ...  184.0      0.0          483.0\n",
              "4097828     4097828       4381108         대곡교  ...  184.0      0.0          483.0\n",
              "4097829     4097829       4381109         대곡교  ...  185.0      0.0          483.0\n",
              "4097830     4097830       4381110         대곡교  ...  185.0      0.0          483.0\n",
              "4097831     4097831       4381111         대곡교  ...  185.0      0.0          483.0\n",
              "\n",
              "[4097832 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MWTcEuZrsFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "d3e5e749-d42e-445c-ea25-5c2eae4ff261"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4097832 entries, 0 to 4097831\n",
            "Data columns (total 15 columns):\n",
            " #   Column              Dtype  \n",
            "---  ------              -----  \n",
            " 0   Unnamed: 0          int64  \n",
            " 1   Unnamed: 0.1        int64  \n",
            " 2   bridge_name         object \n",
            " 3   address             object \n",
            " 4   etc_address         object \n",
            " 5   latitude            float64\n",
            " 6   longitude           float64\n",
            " 7   brid_height_origin  float64\n",
            " 8   location_start      object \n",
            " 9   wl_station_code     int64  \n",
            " 10  rf_station_code     int64  \n",
            " 11  obs_date            object \n",
            " 12  WL                  float64\n",
            " 13  rainfall            float64\n",
            " 14  bridge_height       float64\n",
            "dtypes: float64(6), int64(4), object(5)\n",
            "memory usage: 469.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cub-7bS_MvXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop('Unnamed: 0', axis=1)\n",
        "df = df.drop('Unnamed: 0.1', axis=1)\n",
        "df = df.drop('wl_station_code', axis=1)\n",
        "df = df.drop('rf_station_code', axis=1)\n",
        "df = df.drop('rainfall', axis=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dmEQ7cpNaBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "38b6c3c7-bc98-4639-d773-33d894b9e0e3"
      },
      "source": [
        "df, df.info() # df 컬럼 인덱스 확인"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4097832 entries, 0 to 4097831\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Dtype  \n",
            "---  ------              -----  \n",
            " 0   bridge_name         object \n",
            " 1   address             object \n",
            " 2   etc_address         object \n",
            " 3   latitude            float64\n",
            " 4   longitude           float64\n",
            " 5   brid_height_origin  float64\n",
            " 6   location_start      object \n",
            " 7   obs_date            object \n",
            " 8   WL                  float64\n",
            " 9   bridge_height       float64\n",
            "dtypes: float64(5), object(5)\n",
            "memory usage: 312.6+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(        bridge_name address  ...     WL  bridge_height\n",
              " 0               신원교     경기도  ...    3.0          510.0\n",
              " 1               신원교     경기도  ...    6.0          510.0\n",
              " 2               신원교     경기도  ...   10.0          510.0\n",
              " 3               신원교     경기도  ...   14.0          510.0\n",
              " 4               신원교     경기도  ...   18.0          510.0\n",
              " ...             ...     ...  ...    ...            ...\n",
              " 4097827         대곡교   서울특별시  ...  184.0          483.0\n",
              " 4097828         대곡교   서울특별시  ...  184.0          483.0\n",
              " 4097829         대곡교   서울특별시  ...  185.0          483.0\n",
              " 4097830         대곡교   서울특별시  ...  185.0          483.0\n",
              " 4097831         대곡교   서울특별시  ...  185.0          483.0\n",
              " \n",
              " [4097832 rows x 10 columns], None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf07BdM1MOb_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a5a95b3a-cd2b-4e57-95a4-9464ae5ea3eb"
      },
      "source": [
        "bridge_list = pd.unique(df['bridge_name']).tolist() # 교량 리스트\n",
        "len(bridge_list)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9gT5ZpgL9da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 49개 교량 dataframe 한 번에 어떻게 만들지..\n",
        "lstm_brid_df = {}\n",
        "for i in range(len(bridge_list)):\n",
        "  lstm_brid_df = df[df['bridge_name']==bridge_list[i]].iloc[:-1, [7,8]]\n",
        "  # df[df['bridge_name']==bridge_list[i]]['WL'].plot()\n",
        "  # plt.title(bridge_list[i])\n",
        "  # plt.show()"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SM_DmcC4K3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0c15a38a-bdc0-4385-d73b-2462c8bef757"
      },
      "source": [
        "lstm_brid_df"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs_date</th>\n",
              "      <th>WL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4004514</th>\n",
              "      <td>2010-01-01 00:00:00</td>\n",
              "      <td>178.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004515</th>\n",
              "      <td>2010-01-01 01:00:00</td>\n",
              "      <td>178.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004516</th>\n",
              "      <td>2010-01-01 02:00:00</td>\n",
              "      <td>178.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004517</th>\n",
              "      <td>2010-01-01 03:00:00</td>\n",
              "      <td>178.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004518</th>\n",
              "      <td>2010-01-01 04:00:00</td>\n",
              "      <td>178.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097826</th>\n",
              "      <td>2017-06-26 16:00:00</td>\n",
              "      <td>184.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097827</th>\n",
              "      <td>2017-06-26 17:00:00</td>\n",
              "      <td>184.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097828</th>\n",
              "      <td>2017-06-26 18:00:00</td>\n",
              "      <td>184.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097829</th>\n",
              "      <td>2017-06-26 19:00:00</td>\n",
              "      <td>185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097830</th>\n",
              "      <td>2017-06-26 20:00:00</td>\n",
              "      <td>185.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>93317 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    obs_date     WL\n",
              "4004514  2010-01-01 00:00:00  178.0\n",
              "4004515  2010-01-01 01:00:00  178.0\n",
              "4004516  2010-01-01 02:00:00  178.0\n",
              "4004517  2010-01-01 03:00:00  178.0\n",
              "4004518  2010-01-01 04:00:00  178.0\n",
              "...                      ...    ...\n",
              "4097826  2017-06-26 16:00:00  184.0\n",
              "4097827  2017-06-26 17:00:00  184.0\n",
              "4097828  2017-06-26 18:00:00  184.0\n",
              "4097829  2017-06-26 19:00:00  185.0\n",
              "4097830  2017-06-26 20:00:00  185.0\n",
              "\n",
              "[93317 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-chlM-QfD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e7769653-c675-4239-99ff-da3255ee998b"
      },
      "source": [
        "lstm_df = df[df['bridge_name']=='신원교'].iloc[:-1, [7, 8]] # 신원교 df for lstm\n",
        "lstm_df"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs_date</th>\n",
              "      <th>WL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-02-25 12:00:00</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-02-25 13:00:00</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-02-25 14:00:00</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-02-25 15:00:00</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-02-25 16:00:00</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397888</th>\n",
              "      <td>2020-08-26 20:00:00</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397889</th>\n",
              "      <td>2020-08-26 21:00:00</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397890</th>\n",
              "      <td>2020-08-26 22:00:00</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397891</th>\n",
              "      <td>2020-08-26 23:00:00</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397892</th>\n",
              "      <td>2020-08-27 00:00:00</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111169 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   obs_date    WL\n",
              "0       2010-02-25 12:00:00   3.0\n",
              "1       2010-02-25 13:00:00   6.0\n",
              "2       2010-02-25 14:00:00  10.0\n",
              "3       2010-02-25 15:00:00  14.0\n",
              "4       2010-02-25 16:00:00  18.0\n",
              "...                     ...   ...\n",
              "397888  2020-08-26 20:00:00  68.0\n",
              "397889  2020-08-26 21:00:00  68.0\n",
              "397890  2020-08-26 22:00:00  68.0\n",
              "397891  2020-08-26 23:00:00  69.0\n",
              "397892  2020-08-27 00:00:00  70.0\n",
              "\n",
              "[111169 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH4SGKmqdWlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "b243f590-9282-47da-f84a-92120e89855c"
      },
      "source": [
        "lstm_df = lstm_df.set_index('obs_date')\n",
        "lstm_df"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>obs_date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-02-25 12:00:00</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 13:00:00</th>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 14:00:00</th>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 15:00:00</th>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 16:00:00</th>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-08-26 20:00:00</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-08-26 21:00:00</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-08-26 22:00:00</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-08-26 23:00:00</th>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-08-27 00:00:00</th>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111169 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       WL\n",
              "obs_date                 \n",
              "2010-02-25 12:00:00   3.0\n",
              "2010-02-25 13:00:00   6.0\n",
              "2010-02-25 14:00:00  10.0\n",
              "2010-02-25 15:00:00  14.0\n",
              "2010-02-25 16:00:00  18.0\n",
              "...                   ...\n",
              "2020-08-26 20:00:00  68.0\n",
              "2020-08-26 21:00:00  68.0\n",
              "2020-08-26 22:00:00  68.0\n",
              "2020-08-26 23:00:00  69.0\n",
              "2020-08-27 00:00:00  70.0\n",
              "\n",
              "[111169 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEh2I1tdfaXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "1499269b-cf2b-4a9d-b81e-71c59166f4d6"
      },
      "source": [
        "lstm_df['WL'].plot()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe2e52392e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OCBIO9VMnEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12bf39aa-0183-4d3f-bb89-b1d9005464e6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split_date = '2017-01-01 00:00:00'\n",
        "## X의 train, test용 데이터: 스플릿 기준으로 나누기\n",
        "train = lstm_df.loc[:split_date, ['WL']]\n",
        "test = lstm_df.loc[split_date:, ['WL']]\n",
        "train.shape, test.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((54585, 1), (56586, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_JSkKyvSfBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "db5747bb-85d0-42b0-f964-164bb363f59f"
      },
      "source": [
        "# train, test 데이터 시각화\n",
        "ax = train.plot()\n",
        "test.plot(ax=ax)\n",
        "plt.legend(['train', 'test'])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe2e483a3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ1YgVULSbfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "473463fd-cb4a-41ad-86c2-124fe540964b"
      },
      "source": [
        "# 데이터 스케일링(Scaling)\n",
        "# 마지막으로 MinMaxScaler 클래스를 사용하여 데이터를 스케일링\n",
        "# MinMaxScalar(X)는 데이터의 최대값이 1, 최소값이 0이 되도록 변환\n",
        "# 데이터의 scale을 맞추면 weight의 scale도 일관성 있게 나올 수 있다.\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "\n",
        "train_sc = sc.fit_transform(train)\n",
        "test_sc = sc.transform(test)\n",
        "\n",
        "train_sc"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13539192],\n",
              "       [0.14251781],\n",
              "       [0.152019  ],\n",
              "       ...,\n",
              "       [0.3824228 ],\n",
              "       [0.3824228 ],\n",
              "       [0.3824228 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8qaEawVcQsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "439416ed-db03-4a0f-865f-a853dedb17fa"
      },
      "source": [
        "# 정규화가 완료된 데이터들은 다시 pandas dataframe 데이터 타입으로 변환\n",
        "# dataframe으로 타입을 변경하는 이유는 pandas는 시계열 자료에 대한 다양한 기능을 제공하여 LSTM에서 사용하는 window를 만들기 유용하기 때문\n",
        "train_sc_df = pd.DataFrame(train_sc, columns=['WL'], index=X_train.index)\n",
        "test_sc_df = pd.DataFrame(test_sc, columns=['WL'], index=X_test.index)\n",
        "train_sc_df.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>obs_date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-02-25 12:00:00</th>\n",
              "      <td>0.135392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 13:00:00</th>\n",
              "      <td>0.142518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 14:00:00</th>\n",
              "      <td>0.152019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 15:00:00</th>\n",
              "      <td>0.161520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 16:00:00</th>\n",
              "      <td>0.171021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           WL\n",
              "obs_date                     \n",
              "2010-02-25 12:00:00  0.135392\n",
              "2010-02-25 13:00:00  0.142518\n",
              "2010-02-25 14:00:00  0.152019\n",
              "2010-02-25 15:00:00  0.161520\n",
              "2010-02-25 16:00:00  0.171021"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6H9bIhqcg5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "368c65de-c23b-4158-92db-10a41435c3f0"
      },
      "source": [
        "# sliding window 구성\n",
        "# window: LSTM 훈련을 위한 고정된 사이즈 단위\n",
        "# window 12개로 과거 시간 데이터 12개를 사용해서 다음 시간 단위의 값을 예측\n",
        "for s in range(1, 13):\n",
        "    train_sc_df['shift_{}'.format(s)] = train_sc_df['WL'].shift(s)\n",
        "    test_sc_df['shift_{}'.format(s)] = test_sc_df['WL'].shift(s)\n",
        "\n",
        "train_sc_df.head(13)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WL</th>\n",
              "      <th>shift_1</th>\n",
              "      <th>shift_2</th>\n",
              "      <th>shift_3</th>\n",
              "      <th>shift_4</th>\n",
              "      <th>shift_5</th>\n",
              "      <th>shift_6</th>\n",
              "      <th>shift_7</th>\n",
              "      <th>shift_8</th>\n",
              "      <th>shift_9</th>\n",
              "      <th>shift_10</th>\n",
              "      <th>shift_11</th>\n",
              "      <th>shift_12</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>obs_date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-02-25 12:00:00</th>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 13:00:00</th>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 14:00:00</th>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 15:00:00</th>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 16:00:00</th>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 17:00:00</th>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 18:00:00</th>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 19:00:00</th>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 20:00:00</th>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 21:00:00</th>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 22:00:00</th>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25 23:00:00</th>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-26 00:00:00</th>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           WL   shift_1   shift_2  ...  shift_10  shift_11  shift_12\n",
              "obs_date                                           ...                              \n",
              "2010-02-25 12:00:00  0.135392       NaN       NaN  ...       NaN       NaN       NaN\n",
              "2010-02-25 13:00:00  0.142518  0.135392       NaN  ...       NaN       NaN       NaN\n",
              "2010-02-25 14:00:00  0.152019  0.142518  0.135392  ...       NaN       NaN       NaN\n",
              "2010-02-25 15:00:00  0.161520  0.152019  0.142518  ...       NaN       NaN       NaN\n",
              "2010-02-25 16:00:00  0.171021  0.161520  0.152019  ...       NaN       NaN       NaN\n",
              "2010-02-25 17:00:00  0.180523  0.171021  0.161520  ...       NaN       NaN       NaN\n",
              "2010-02-25 18:00:00  0.187648  0.180523  0.171021  ...       NaN       NaN       NaN\n",
              "2010-02-25 19:00:00  0.192399  0.187648  0.180523  ...       NaN       NaN       NaN\n",
              "2010-02-25 20:00:00  0.192399  0.192399  0.187648  ...       NaN       NaN       NaN\n",
              "2010-02-25 21:00:00  0.194774  0.192399  0.192399  ...       NaN       NaN       NaN\n",
              "2010-02-25 22:00:00  0.194774  0.194774  0.192399  ...  0.135392       NaN       NaN\n",
              "2010-02-25 23:00:00  0.194774  0.194774  0.194774  ...  0.142518  0.135392       NaN\n",
              "2010-02-26 00:00:00  0.192399  0.194774  0.194774  ...  0.152019  0.142518  0.135392\n",
              "\n",
              "[13 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl_HkNuiiwUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "fd65490d-ce93-426d-90b7-08e24f7f9b89"
      },
      "source": [
        "# 과거 12개 하천 수위 지수들이 train 속성들이 되고, '현재 하천 수위의 지수'가 y(target)이 된다.\n",
        "# 데이터에서 결측값 제거\n",
        "# 전체 데이터를 train 데이터, test 데이터로 분리\n",
        "# 각각의 train, test 데이터는 속성과 타겟열로 분리\n",
        "X_train = train_sc_df.dropna().drop('WL', axis=1)\n",
        "y_train = train_sc_df.dropna()[['WL']]\n",
        "\n",
        "X_test = test_sc_df.dropna().drop('WL', axis=1)\n",
        "y_test = test_sc_df.dropna()[['WL']]\n",
        "\n",
        "X_train.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>shift_1</th>\n",
              "      <th>shift_2</th>\n",
              "      <th>shift_3</th>\n",
              "      <th>shift_4</th>\n",
              "      <th>shift_5</th>\n",
              "      <th>shift_6</th>\n",
              "      <th>shift_7</th>\n",
              "      <th>shift_8</th>\n",
              "      <th>shift_9</th>\n",
              "      <th>shift_10</th>\n",
              "      <th>shift_11</th>\n",
              "      <th>shift_12</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>obs_date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-02-26 00:00:00</th>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "      <td>0.135392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-26 01:00:00</th>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "      <td>0.142518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-26 02:00:00</th>\n",
              "      <td>0.190024</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>0.152019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-26 03:00:00</th>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.190024</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "      <td>0.161520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-26 04:00:00</th>\n",
              "      <td>0.185273</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.190024</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.194774</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.192399</td>\n",
              "      <td>0.187648</td>\n",
              "      <td>0.180523</td>\n",
              "      <td>0.171021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      shift_1   shift_2   shift_3  ...  shift_10  shift_11  shift_12\n",
              "obs_date                                           ...                              \n",
              "2010-02-26 00:00:00  0.194774  0.194774  0.194774  ...  0.152019  0.142518  0.135392\n",
              "2010-02-26 01:00:00  0.192399  0.194774  0.194774  ...  0.161520  0.152019  0.142518\n",
              "2010-02-26 02:00:00  0.190024  0.192399  0.194774  ...  0.171021  0.161520  0.152019\n",
              "2010-02-26 03:00:00  0.187648  0.190024  0.192399  ...  0.180523  0.171021  0.161520\n",
              "2010-02-26 04:00:00  0.185273  0.187648  0.190024  ...  0.187648  0.180523  0.171021\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1CX34dkS1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "9c5db210-a80c-4b9f-cbfe-b024e5000428"
      },
      "source": [
        "# dataframe 타입이었던 train, test 데이터들을 values로 dataframe의 numpy 표현형만 가져옴\n",
        "# sklearn을 비롯해서 기계학습 패키지들은 train, test 데이터로 numpy의 ndarray 타입을 지원\n",
        "# values를 사용하기 전 X_train은 DataFrame 타입, values를 사용한 후 numpy.ndarray로 변경 확인\n",
        "print(type(X_train))\n",
        "X_train = X_train.values\n",
        "print(type(X_train))\n",
        "X_test= X_test.values\n",
        "y_train = y_train.values\n",
        "y_test = y_test.values\n",
        " \n",
        "# X_train 데이터는 54573개 데이터 갯수, 12개 slot\n",
        "# y_train 데이터는 54573개 데이터, 1개의 target\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'numpy.ndarray'>\n",
            "(54573, 12)\n",
            "(54573, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8945k9WdkW37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8afd3245-29d7-4e63-f627-93f4df2a28b4"
      },
      "source": [
        "# 최종 훈련 데이터 생성을 위해 keras의 LSTM에 필요한 3차원 데이터로 변환\n",
        "# 최종 데이터 shape이 (size, timestamp, feature) 형태로 나타나야함.\n",
        "# 속성이 하천 수위 지수 한가지이므로 1을 입력, n 개의 속성을 사용할 경우 feature 순서에 n의 값을 입력\n",
        "X_train_t = X_train.reshape(X_train.shape[0], 12, 1)\n",
        "X_test_t = X_test.reshape(X_test.shape[0], 12, 1)\n",
        "\n",
        "print(\"최종 DATA\")\n",
        "print(X_train_t.shape)\n",
        "print(X_train_t)\n",
        "print(y_train)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최종 DATA\n",
            "(54573, 12, 1)\n",
            "[[[0.19477435]\n",
            "  [0.19477435]\n",
            "  [0.19477435]\n",
            "  ...\n",
            "  [0.152019  ]\n",
            "  [0.14251781]\n",
            "  [0.13539192]]\n",
            "\n",
            " [[0.19239905]\n",
            "  [0.19477435]\n",
            "  [0.19477435]\n",
            "  ...\n",
            "  [0.16152019]\n",
            "  [0.152019  ]\n",
            "  [0.14251781]]\n",
            "\n",
            " [[0.19002375]\n",
            "  [0.19239905]\n",
            "  [0.19477435]\n",
            "  ...\n",
            "  [0.17102138]\n",
            "  [0.16152019]\n",
            "  [0.152019  ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.3824228 ]\n",
            "  [0.3824228 ]\n",
            "  [0.3824228 ]\n",
            "  ...\n",
            "  [0.3824228 ]\n",
            "  [0.3824228 ]\n",
            "  [0.3824228 ]]\n",
            "\n",
            " [[0.3824228 ]\n",
            "  [0.3824228 ]\n",
            "  [0.3824228 ]\n",
            "  ...\n",
            "  [0.3824228 ]\n",
            "  [0.3824228 ]\n",
            "  [0.3824228 ]]\n",
            "\n",
            " [[0.3824228 ]\n",
            "  [0.3824228 ]\n",
            "  [0.3824228 ]\n",
            "  ...\n",
            "  [0.3824228 ]\n",
            "  [0.3824228 ]\n",
            "  [0.3824228 ]]]\n",
            "[[0.19239905]\n",
            " [0.19002375]\n",
            " [0.18764846]\n",
            " ...\n",
            " [0.3824228 ]\n",
            " [0.3824228 ]\n",
            " [0.3824228 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MzawigPkhLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "172303f2-79c7-46b7-82f7-fbaf40e1f0a1"
      },
      "source": [
        "# LSTM 모델의 입력은 기본적으로 3차원 구조(최종 훈련 데이터를 생성하기 위해 3차원 데이터로 변환 필수)\n",
        "# 첫 번째 차원: 데이터(sample/batch) 갯수, 두번째 차원: 시간축의 차원(time step size),\n",
        "# 마지막 차원: LSTM 입력층에 입력되는 데이터(feature) 갯수\n",
        "from keras.layers import LSTM \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "import keras.backend as K \n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "\n",
        "# 모델 생성전에 tensorflow의 graph 영역을 clear한다.\n",
        "K.clear_session()\n",
        "\n",
        "# Sequeatial Model: 레이어들을 선형으로 쌓는 모델\n",
        "model = Sequential() \n",
        "# LSTM 레이어: 20메모리 셀, (timestep, feature)\n",
        "model.add(LSTM(20, input_shape=(1, 1))) \n",
        "# Dense 레이어: output = 1(예측하고자 하는 target갯수)\n",
        "model.add(Dense(1)) \n",
        "# optimizer: 훈련과정 설정, loss: 최적화 과정에서 최소화될 손실 함수 설정, metrics: 훈련 모니터링위해 사용\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error']) # metrics = ['accuracy']는 classification에 사용\n",
        "model.summary()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 20)                1760      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 1,781\n",
            "Trainable params: 1,781\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l37RmHp5eDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 체크 포인트 만들어서 모델 저장\n",
        "# 모델 저장 폴더 설정\n",
        "MODEL_DIR = './model/'   #같은 폴더 내에 model이라는 폴더가 없다면 만들어줘라\n",
        "if not os.path.exists(MODEL_DIR):      \n",
        "    os.mkdir(MODEL_DIR)    #mkdir이 폴더 생성 함수\n",
        "    \n",
        "# 모델 저장 조건 설정\n",
        "modelpath = './model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
        "checkpointer = ModelCheckpoint(filepath = modelpath, monitor='val_loss', verbose = 1, save_best_only = True)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DocFaTi8ktVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51e4c193-c2ac-486c-afa3-2444eb116b44"
      },
      "source": [
        "# 과적합 방지: Early stopping 설정\n",
        "# patience 횟수 만큼 정확도가 개선이 안되면 학습 중단\n",
        "early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
        "\n",
        "hist = model.fit(X_train_t, y_train, validation_split=0.2, epochs=500,\n",
        "          batch_size=20, verbose=1, callbacks=[checkpointer, early_stop])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input Tensor(\"lstm_input:0\", shape=(None, 1, 1), dtype=float32), but it was called on an input with incompatible shape (None, 12, 1).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input Tensor(\"lstm_input:0\", shape=(None, 1, 1), dtype=float32), but it was called on an input with incompatible shape (None, 12, 1).\n",
            "2177/2183 [============================>.] - ETA: 0s - loss: 3.9799e-04 - mean_squared_error: 3.9799e-04WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input Tensor(\"lstm_input:0\", shape=(None, 1, 1), dtype=float32), but it was called on an input with incompatible shape (None, 12, 1).\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00006, saving model to ./model/01-0.0001.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.9724e-04 - mean_squared_error: 3.9724e-04 - val_loss: 5.6338e-05 - val_mean_squared_error: 5.6338e-05\n",
            "Epoch 2/500\n",
            "2173/2183 [============================>.] - ETA: 0s - loss: 1.8945e-04 - mean_squared_error: 1.8945e-04\n",
            "Epoch 00002: val_loss did not improve from 0.00006\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 1.9023e-04 - mean_squared_error: 1.9023e-04 - val_loss: 8.8811e-05 - val_mean_squared_error: 8.8811e-05\n",
            "Epoch 3/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 1.7881e-04 - mean_squared_error: 1.7881e-04\n",
            "Epoch 00003: val_loss did not improve from 0.00006\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 1.7874e-04 - mean_squared_error: 1.7874e-04 - val_loss: 8.0673e-05 - val_mean_squared_error: 8.0673e-05\n",
            "Epoch 4/500\n",
            "2174/2183 [============================>.] - ETA: 0s - loss: 1.5513e-04 - mean_squared_error: 1.5513e-04\n",
            "Epoch 00004: val_loss improved from 0.00006 to 0.00004, saving model to ./model/04-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 1.5477e-04 - mean_squared_error: 1.5477e-04 - val_loss: 4.1559e-05 - val_mean_squared_error: 4.1559e-05\n",
            "Epoch 5/500\n",
            "2173/2183 [============================>.] - ETA: 0s - loss: 1.5233e-04 - mean_squared_error: 1.5233e-04\n",
            "Epoch 00005: val_loss improved from 0.00004 to 0.00004, saving model to ./model/05-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 1.5193e-04 - mean_squared_error: 1.5193e-04 - val_loss: 3.7915e-05 - val_mean_squared_error: 3.7915e-05\n",
            "Epoch 6/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 1.3274e-04 - mean_squared_error: 1.3274e-04\n",
            "Epoch 00006: val_loss did not improve from 0.00004\n",
            "2183/2183 [==============================] - 12s 6ms/step - loss: 1.3252e-04 - mean_squared_error: 1.3252e-04 - val_loss: 9.7205e-05 - val_mean_squared_error: 9.7205e-05\n",
            "Epoch 7/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 1.2254e-04 - mean_squared_error: 1.2254e-04\n",
            "Epoch 00007: val_loss did not improve from 0.00004\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 1.2241e-04 - mean_squared_error: 1.2241e-04 - val_loss: 1.0281e-04 - val_mean_squared_error: 1.0281e-04\n",
            "Epoch 8/500\n",
            "2182/2183 [============================>.] - ETA: 0s - loss: 1.1617e-04 - mean_squared_error: 1.1617e-04\n",
            "Epoch 00008: val_loss did not improve from 0.00004\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 1.1641e-04 - mean_squared_error: 1.1641e-04 - val_loss: 2.3255e-04 - val_mean_squared_error: 2.3255e-04\n",
            "Epoch 9/500\n",
            "2176/2183 [============================>.] - ETA: 0s - loss: 1.1381e-04 - mean_squared_error: 1.1381e-04\n",
            "Epoch 00009: val_loss did not improve from 0.00004\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 1.1478e-04 - mean_squared_error: 1.1478e-04 - val_loss: 2.8947e-04 - val_mean_squared_error: 2.8947e-04\n",
            "Epoch 10/500\n",
            "2174/2183 [============================>.] - ETA: 0s - loss: 1.0699e-04 - mean_squared_error: 1.0699e-04\n",
            "Epoch 00010: val_loss did not improve from 0.00004\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 1.0675e-04 - mean_squared_error: 1.0675e-04 - val_loss: 1.0668e-04 - val_mean_squared_error: 1.0668e-04\n",
            "Epoch 11/500\n",
            "2177/2183 [============================>.] - ETA: 0s - loss: 9.8308e-05 - mean_squared_error: 9.8308e-05\n",
            "Epoch 00011: val_loss did not improve from 0.00004\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 9.8147e-05 - mean_squared_error: 9.8147e-05 - val_loss: 4.7659e-05 - val_mean_squared_error: 4.7659e-05\n",
            "Epoch 12/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 9.1090e-05 - mean_squared_error: 9.1090e-05\n",
            "Epoch 00012: val_loss improved from 0.00004 to 0.00003, saving model to ./model/12-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 9.1000e-05 - mean_squared_error: 9.1000e-05 - val_loss: 3.1319e-05 - val_mean_squared_error: 3.1319e-05\n",
            "Epoch 13/500\n",
            "2176/2183 [============================>.] - ETA: 0s - loss: 8.9407e-05 - mean_squared_error: 8.9407e-05\n",
            "Epoch 00013: val_loss improved from 0.00003 to 0.00003, saving model to ./model/13-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 8.9640e-05 - mean_squared_error: 8.9640e-05 - val_loss: 2.8981e-05 - val_mean_squared_error: 2.8981e-05\n",
            "Epoch 14/500\n",
            "2182/2183 [============================>.] - ETA: 0s - loss: 8.2348e-05 - mean_squared_error: 8.2348e-05\n",
            "Epoch 00014: val_loss did not improve from 0.00003\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 8.2319e-05 - mean_squared_error: 8.2319e-05 - val_loss: 3.2568e-05 - val_mean_squared_error: 3.2568e-05\n",
            "Epoch 15/500\n",
            "2176/2183 [============================>.] - ETA: 0s - loss: 8.3165e-05 - mean_squared_error: 8.3165e-05\n",
            "Epoch 00015: val_loss did not improve from 0.00003\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 8.3144e-05 - mean_squared_error: 8.3144e-05 - val_loss: 9.9116e-05 - val_mean_squared_error: 9.9116e-05\n",
            "Epoch 16/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 8.0738e-05 - mean_squared_error: 8.0738e-05\n",
            "Epoch 00016: val_loss improved from 0.00003 to 0.00003, saving model to ./model/16-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 8.0556e-05 - mean_squared_error: 8.0556e-05 - val_loss: 2.6234e-05 - val_mean_squared_error: 2.6234e-05\n",
            "Epoch 17/500\n",
            "2177/2183 [============================>.] - ETA: 0s - loss: 7.8578e-05 - mean_squared_error: 7.8578e-05\n",
            "Epoch 00017: val_loss did not improve from 0.00003\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 7.8465e-05 - mean_squared_error: 7.8465e-05 - val_loss: 3.1453e-05 - val_mean_squared_error: 3.1453e-05\n",
            "Epoch 18/500\n",
            "2177/2183 [============================>.] - ETA: 0s - loss: 7.7215e-05 - mean_squared_error: 7.7215e-05\n",
            "Epoch 00018: val_loss did not improve from 0.00003\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 7.7228e-05 - mean_squared_error: 7.7228e-05 - val_loss: 3.1777e-05 - val_mean_squared_error: 3.1777e-05\n",
            "Epoch 19/500\n",
            "2178/2183 [============================>.] - ETA: 0s - loss: 7.5411e-05 - mean_squared_error: 7.5411e-05\n",
            "Epoch 00019: val_loss did not improve from 0.00003\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 7.5581e-05 - mean_squared_error: 7.5581e-05 - val_loss: 7.2763e-05 - val_mean_squared_error: 7.2763e-05\n",
            "Epoch 20/500\n",
            "2174/2183 [============================>.] - ETA: 0s - loss: 7.4921e-05 - mean_squared_error: 7.4921e-05\n",
            "Epoch 00020: val_loss improved from 0.00003 to 0.00003, saving model to ./model/20-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 7.4765e-05 - mean_squared_error: 7.4765e-05 - val_loss: 2.5132e-05 - val_mean_squared_error: 2.5132e-05\n",
            "Epoch 21/500\n",
            "2181/2183 [============================>.] - ETA: 0s - loss: 7.0660e-05 - mean_squared_error: 7.0660e-05\n",
            "Epoch 00021: val_loss did not improve from 0.00003\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 7.0680e-05 - mean_squared_error: 7.0680e-05 - val_loss: 5.3721e-05 - val_mean_squared_error: 5.3721e-05\n",
            "Epoch 22/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 7.0215e-05 - mean_squared_error: 7.0215e-05\n",
            "Epoch 00022: val_loss did not improve from 0.00003\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 7.0215e-05 - mean_squared_error: 7.0215e-05 - val_loss: 8.0026e-05 - val_mean_squared_error: 8.0026e-05\n",
            "Epoch 23/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 7.4313e-05 - mean_squared_error: 7.4313e-05\n",
            "Epoch 00023: val_loss did not improve from 0.00003\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 7.4300e-05 - mean_squared_error: 7.4300e-05 - val_loss: 9.4198e-05 - val_mean_squared_error: 9.4198e-05\n",
            "Epoch 24/500\n",
            "2178/2183 [============================>.] - ETA: 0s - loss: 6.6959e-05 - mean_squared_error: 6.6959e-05\n",
            "Epoch 00024: val_loss did not improve from 0.00003\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 6.6832e-05 - mean_squared_error: 6.6832e-05 - val_loss: 3.2028e-05 - val_mean_squared_error: 3.2028e-05\n",
            "Epoch 25/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 6.7673e-05 - mean_squared_error: 6.7673e-05\n",
            "Epoch 00025: val_loss did not improve from 0.00003\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 6.7563e-05 - mean_squared_error: 6.7563e-05 - val_loss: 2.6595e-05 - val_mean_squared_error: 2.6595e-05\n",
            "Epoch 26/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 6.7852e-05 - mean_squared_error: 6.7852e-05\n",
            "Epoch 00026: val_loss improved from 0.00003 to 0.00002, saving model to ./model/26-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 6.7793e-05 - mean_squared_error: 6.7793e-05 - val_loss: 2.2983e-05 - val_mean_squared_error: 2.2983e-05\n",
            "Epoch 27/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 6.6753e-05 - mean_squared_error: 6.6753e-05\n",
            "Epoch 00027: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 6.6667e-05 - mean_squared_error: 6.6667e-05 - val_loss: 2.4245e-05 - val_mean_squared_error: 2.4245e-05\n",
            "Epoch 28/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 6.4216e-05 - mean_squared_error: 6.4216e-05\n",
            "Epoch 00028: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 6.4125e-05 - mean_squared_error: 6.4125e-05 - val_loss: 3.1463e-05 - val_mean_squared_error: 3.1463e-05\n",
            "Epoch 29/500\n",
            "2181/2183 [============================>.] - ETA: 0s - loss: 6.5053e-05 - mean_squared_error: 6.5053e-05\n",
            "Epoch 00029: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 6.5000e-05 - mean_squared_error: 6.5000e-05 - val_loss: 2.6969e-05 - val_mean_squared_error: 2.6969e-05\n",
            "Epoch 30/500\n",
            "2176/2183 [============================>.] - ETA: 0s - loss: 6.1277e-05 - mean_squared_error: 6.1277e-05\n",
            "Epoch 00030: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 6.1222e-05 - mean_squared_error: 6.1222e-05 - val_loss: 4.0509e-05 - val_mean_squared_error: 4.0509e-05\n",
            "Epoch 31/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 6.2095e-05 - mean_squared_error: 6.2095e-05\n",
            "Epoch 00031: val_loss improved from 0.00002 to 0.00002, saving model to ./model/31-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 6.2007e-05 - mean_squared_error: 6.2007e-05 - val_loss: 2.2731e-05 - val_mean_squared_error: 2.2731e-05\n",
            "Epoch 32/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 6.0052e-05 - mean_squared_error: 6.0052e-05\n",
            "Epoch 00032: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 6.0051e-05 - mean_squared_error: 6.0051e-05 - val_loss: 3.8042e-05 - val_mean_squared_error: 3.8042e-05\n",
            "Epoch 33/500\n",
            "2176/2183 [============================>.] - ETA: 0s - loss: 6.0417e-05 - mean_squared_error: 6.0417e-05\n",
            "Epoch 00033: val_loss improved from 0.00002 to 0.00002, saving model to ./model/33-0.0000.hdf5\n",
            "2183/2183 [==============================] - 12s 5ms/step - loss: 6.0253e-05 - mean_squared_error: 6.0253e-05 - val_loss: 2.2606e-05 - val_mean_squared_error: 2.2606e-05\n",
            "Epoch 34/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 5.8723e-05 - mean_squared_error: 5.8723e-05\n",
            "Epoch 00034: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.9067e-05 - mean_squared_error: 5.9067e-05 - val_loss: 3.8192e-05 - val_mean_squared_error: 3.8192e-05\n",
            "Epoch 35/500\n",
            "2178/2183 [============================>.] - ETA: 0s - loss: 5.7373e-05 - mean_squared_error: 5.7373e-05\n",
            "Epoch 00035: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.7550e-05 - mean_squared_error: 5.7550e-05 - val_loss: 4.8447e-05 - val_mean_squared_error: 4.8447e-05\n",
            "Epoch 36/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 5.6205e-05 - mean_squared_error: 5.6205e-05\n",
            "Epoch 00036: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.6145e-05 - mean_squared_error: 5.6145e-05 - val_loss: 3.8462e-05 - val_mean_squared_error: 3.8462e-05\n",
            "Epoch 37/500\n",
            "2176/2183 [============================>.] - ETA: 0s - loss: 5.7652e-05 - mean_squared_error: 5.7652e-05\n",
            "Epoch 00037: val_loss improved from 0.00002 to 0.00002, saving model to ./model/37-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.7607e-05 - mean_squared_error: 5.7607e-05 - val_loss: 2.1877e-05 - val_mean_squared_error: 2.1877e-05\n",
            "Epoch 38/500\n",
            "2173/2183 [============================>.] - ETA: 0s - loss: 5.6192e-05 - mean_squared_error: 5.6192e-05\n",
            "Epoch 00038: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.6315e-05 - mean_squared_error: 5.6315e-05 - val_loss: 3.6204e-05 - val_mean_squared_error: 3.6204e-05\n",
            "Epoch 39/500\n",
            "2182/2183 [============================>.] - ETA: 0s - loss: 5.6940e-05 - mean_squared_error: 5.6940e-05\n",
            "Epoch 00039: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.6917e-05 - mean_squared_error: 5.6917e-05 - val_loss: 2.2759e-05 - val_mean_squared_error: 2.2759e-05\n",
            "Epoch 40/500\n",
            "2176/2183 [============================>.] - ETA: 0s - loss: 5.1454e-05 - mean_squared_error: 5.1454e-05\n",
            "Epoch 00040: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.2889e-05 - mean_squared_error: 5.2889e-05 - val_loss: 9.9442e-05 - val_mean_squared_error: 9.9442e-05\n",
            "Epoch 41/500\n",
            "2182/2183 [============================>.] - ETA: 0s - loss: 5.6675e-05 - mean_squared_error: 5.6675e-05\n",
            "Epoch 00041: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.6654e-05 - mean_squared_error: 5.6654e-05 - val_loss: 2.3745e-05 - val_mean_squared_error: 2.3745e-05\n",
            "Epoch 42/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 5.4095e-05 - mean_squared_error: 5.4095e-05\n",
            "Epoch 00042: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.3952e-05 - mean_squared_error: 5.3952e-05 - val_loss: 2.9501e-05 - val_mean_squared_error: 2.9501e-05\n",
            "Epoch 43/500\n",
            "2181/2183 [============================>.] - ETA: 0s - loss: 5.1971e-05 - mean_squared_error: 5.1971e-05\n",
            "Epoch 00043: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.2147e-05 - mean_squared_error: 5.2147e-05 - val_loss: 2.4532e-05 - val_mean_squared_error: 2.4532e-05\n",
            "Epoch 44/500\n",
            "2174/2183 [============================>.] - ETA: 0s - loss: 5.3188e-05 - mean_squared_error: 5.3188e-05\n",
            "Epoch 00044: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.3118e-05 - mean_squared_error: 5.3118e-05 - val_loss: 3.3551e-05 - val_mean_squared_error: 3.3551e-05\n",
            "Epoch 45/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 5.1321e-05 - mean_squared_error: 5.1321e-05\n",
            "Epoch 00045: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.1263e-05 - mean_squared_error: 5.1263e-05 - val_loss: 2.4951e-05 - val_mean_squared_error: 2.4951e-05\n",
            "Epoch 46/500\n",
            "2178/2183 [============================>.] - ETA: 0s - loss: 5.0879e-05 - mean_squared_error: 5.0879e-05\n",
            "Epoch 00046: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.0810e-05 - mean_squared_error: 5.0810e-05 - val_loss: 2.9963e-05 - val_mean_squared_error: 2.9963e-05\n",
            "Epoch 47/500\n",
            "2172/2183 [============================>.] - ETA: 0s - loss: 5.2502e-05 - mean_squared_error: 5.2502e-05\n",
            "Epoch 00047: val_loss improved from 0.00002 to 0.00002, saving model to ./model/47-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.2274e-05 - mean_squared_error: 5.2274e-05 - val_loss: 2.1775e-05 - val_mean_squared_error: 2.1775e-05\n",
            "Epoch 48/500\n",
            "2182/2183 [============================>.] - ETA: 0s - loss: 5.0983e-05 - mean_squared_error: 5.0983e-05\n",
            "Epoch 00048: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 5.0965e-05 - mean_squared_error: 5.0965e-05 - val_loss: 3.3326e-05 - val_mean_squared_error: 3.3326e-05\n",
            "Epoch 49/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 4.9622e-05 - mean_squared_error: 4.9622e-05\n",
            "Epoch 00049: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.9622e-05 - mean_squared_error: 4.9622e-05 - val_loss: 5.6836e-05 - val_mean_squared_error: 5.6836e-05\n",
            "Epoch 50/500\n",
            "2178/2183 [============================>.] - ETA: 0s - loss: 4.9490e-05 - mean_squared_error: 4.9490e-05\n",
            "Epoch 00050: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.9426e-05 - mean_squared_error: 4.9426e-05 - val_loss: 3.1620e-05 - val_mean_squared_error: 3.1620e-05\n",
            "Epoch 51/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 4.9218e-05 - mean_squared_error: 4.9218e-05\n",
            "Epoch 00051: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.9218e-05 - mean_squared_error: 4.9218e-05 - val_loss: 4.4850e-05 - val_mean_squared_error: 4.4850e-05\n",
            "Epoch 52/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 4.8719e-05 - mean_squared_error: 4.8719e-05\n",
            "Epoch 00052: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.8697e-05 - mean_squared_error: 4.8697e-05 - val_loss: 2.7562e-05 - val_mean_squared_error: 2.7562e-05\n",
            "Epoch 53/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 4.8024e-05 - mean_squared_error: 4.8024e-05\n",
            "Epoch 00053: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 12s 6ms/step - loss: 4.7982e-05 - mean_squared_error: 4.7982e-05 - val_loss: 2.9695e-05 - val_mean_squared_error: 2.9695e-05\n",
            "Epoch 54/500\n",
            "2181/2183 [============================>.] - ETA: 0s - loss: 4.6290e-05 - mean_squared_error: 4.6290e-05\n",
            "Epoch 00054: val_loss improved from 0.00002 to 0.00002, saving model to ./model/54-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.6256e-05 - mean_squared_error: 4.6256e-05 - val_loss: 2.0936e-05 - val_mean_squared_error: 2.0936e-05\n",
            "Epoch 55/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 4.7763e-05 - mean_squared_error: 4.7763e-05\n",
            "Epoch 00055: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.7633e-05 - mean_squared_error: 4.7633e-05 - val_loss: 2.3891e-05 - val_mean_squared_error: 2.3891e-05\n",
            "Epoch 56/500\n",
            "2182/2183 [============================>.] - ETA: 0s - loss: 4.6654e-05 - mean_squared_error: 4.6654e-05\n",
            "Epoch 00056: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.6641e-05 - mean_squared_error: 4.6641e-05 - val_loss: 3.4754e-05 - val_mean_squared_error: 3.4754e-05\n",
            "Epoch 57/500\n",
            "2178/2183 [============================>.] - ETA: 0s - loss: 4.7371e-05 - mean_squared_error: 4.7371e-05\n",
            "Epoch 00057: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 12s 5ms/step - loss: 4.7297e-05 - mean_squared_error: 4.7297e-05 - val_loss: 2.5491e-05 - val_mean_squared_error: 2.5491e-05\n",
            "Epoch 58/500\n",
            "2182/2183 [============================>.] - ETA: 0s - loss: 4.6463e-05 - mean_squared_error: 4.6463e-05\n",
            "Epoch 00058: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.6445e-05 - mean_squared_error: 4.6445e-05 - val_loss: 3.2582e-05 - val_mean_squared_error: 3.2582e-05\n",
            "Epoch 59/500\n",
            "2182/2183 [============================>.] - ETA: 0s - loss: 4.6547e-05 - mean_squared_error: 4.6547e-05\n",
            "Epoch 00059: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.6531e-05 - mean_squared_error: 4.6531e-05 - val_loss: 2.7850e-05 - val_mean_squared_error: 2.7850e-05\n",
            "Epoch 60/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 4.5866e-05 - mean_squared_error: 4.5866e-05\n",
            "Epoch 00060: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.5815e-05 - mean_squared_error: 4.5815e-05 - val_loss: 2.8320e-05 - val_mean_squared_error: 2.8320e-05\n",
            "Epoch 61/500\n",
            "2178/2183 [============================>.] - ETA: 0s - loss: 4.6433e-05 - mean_squared_error: 4.6433e-05\n",
            "Epoch 00061: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 12s 5ms/step - loss: 4.6359e-05 - mean_squared_error: 4.6359e-05 - val_loss: 2.2101e-05 - val_mean_squared_error: 2.2101e-05\n",
            "Epoch 62/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 4.4684e-05 - mean_squared_error: 4.4684e-05\n",
            "Epoch 00062: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.4652e-05 - mean_squared_error: 4.4652e-05 - val_loss: 2.7239e-05 - val_mean_squared_error: 2.7239e-05\n",
            "Epoch 63/500\n",
            "2181/2183 [============================>.] - ETA: 0s - loss: 4.3130e-05 - mean_squared_error: 4.3130e-05\n",
            "Epoch 00063: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.3097e-05 - mean_squared_error: 4.3097e-05 - val_loss: 2.2212e-05 - val_mean_squared_error: 2.2212e-05\n",
            "Epoch 64/500\n",
            "2181/2183 [============================>.] - ETA: 0s - loss: 4.3335e-05 - mean_squared_error: 4.3335e-05\n",
            "Epoch 00064: val_loss improved from 0.00002 to 0.00002, saving model to ./model/64-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.3301e-05 - mean_squared_error: 4.3301e-05 - val_loss: 1.9270e-05 - val_mean_squared_error: 1.9270e-05\n",
            "Epoch 65/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 4.4287e-05 - mean_squared_error: 4.4287e-05\n",
            "Epoch 00065: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.4280e-05 - mean_squared_error: 4.4280e-05 - val_loss: 2.2121e-05 - val_mean_squared_error: 2.2121e-05\n",
            "Epoch 66/500\n",
            "2177/2183 [============================>.] - ETA: 0s - loss: 4.2513e-05 - mean_squared_error: 4.2513e-05\n",
            "Epoch 00066: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.2421e-05 - mean_squared_error: 4.2421e-05 - val_loss: 2.3883e-05 - val_mean_squared_error: 2.3883e-05\n",
            "Epoch 67/500\n",
            "2174/2183 [============================>.] - ETA: 0s - loss: 4.3630e-05 - mean_squared_error: 4.3630e-05\n",
            "Epoch 00067: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.3752e-05 - mean_squared_error: 4.3752e-05 - val_loss: 3.0988e-05 - val_mean_squared_error: 3.0988e-05\n",
            "Epoch 68/500\n",
            "2173/2183 [============================>.] - ETA: 0s - loss: 4.3060e-05 - mean_squared_error: 4.3060e-05\n",
            "Epoch 00068: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.3244e-05 - mean_squared_error: 4.3244e-05 - val_loss: 3.6435e-05 - val_mean_squared_error: 3.6435e-05\n",
            "Epoch 69/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 4.2151e-05 - mean_squared_error: 4.2151e-05\n",
            "Epoch 00069: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.2087e-05 - mean_squared_error: 4.2087e-05 - val_loss: 2.4200e-05 - val_mean_squared_error: 2.4200e-05\n",
            "Epoch 70/500\n",
            "2173/2183 [============================>.] - ETA: 0s - loss: 4.1162e-05 - mean_squared_error: 4.1162e-05\n",
            "Epoch 00070: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.1058e-05 - mean_squared_error: 4.1058e-05 - val_loss: 2.5176e-05 - val_mean_squared_error: 2.5176e-05\n",
            "Epoch 71/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 4.1513e-05 - mean_squared_error: 4.1513e-05\n",
            "Epoch 00071: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.1504e-05 - mean_squared_error: 4.1504e-05 - val_loss: 3.4708e-05 - val_mean_squared_error: 3.4708e-05\n",
            "Epoch 72/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 4.0955e-05 - mean_squared_error: 4.0955e-05\n",
            "Epoch 00072: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.0852e-05 - mean_squared_error: 4.0852e-05 - val_loss: 4.3741e-05 - val_mean_squared_error: 4.3741e-05\n",
            "Epoch 73/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 4.1302e-05 - mean_squared_error: 4.1302e-05\n",
            "Epoch 00073: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.1302e-05 - mean_squared_error: 4.1302e-05 - val_loss: 2.5348e-05 - val_mean_squared_error: 2.5348e-05\n",
            "Epoch 74/500\n",
            "2176/2183 [============================>.] - ETA: 0s - loss: 4.0169e-05 - mean_squared_error: 4.0169e-05\n",
            "Epoch 00074: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.0131e-05 - mean_squared_error: 4.0131e-05 - val_loss: 2.5046e-05 - val_mean_squared_error: 2.5046e-05\n",
            "Epoch 75/500\n",
            "2177/2183 [============================>.] - ETA: 0s - loss: 4.0331e-05 - mean_squared_error: 4.0331e-05\n",
            "Epoch 00075: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.0239e-05 - mean_squared_error: 4.0239e-05 - val_loss: 2.4139e-05 - val_mean_squared_error: 2.4139e-05\n",
            "Epoch 76/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 4.1709e-05 - mean_squared_error: 4.1709e-05\n",
            "Epoch 00076: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.1667e-05 - mean_squared_error: 4.1667e-05 - val_loss: 2.3791e-05 - val_mean_squared_error: 2.3791e-05\n",
            "Epoch 77/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 3.9203e-05 - mean_squared_error: 3.9203e-05\n",
            "Epoch 00077: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.9203e-05 - mean_squared_error: 3.9203e-05 - val_loss: 2.1920e-05 - val_mean_squared_error: 2.1920e-05\n",
            "Epoch 78/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 4.0957e-05 - mean_squared_error: 4.0957e-05\n",
            "Epoch 00078: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 4.0905e-05 - mean_squared_error: 4.0905e-05 - val_loss: 3.3390e-05 - val_mean_squared_error: 3.3390e-05\n",
            "Epoch 79/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 3.9723e-05 - mean_squared_error: 3.9723e-05\n",
            "Epoch 00079: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.9658e-05 - mean_squared_error: 3.9658e-05 - val_loss: 2.2825e-05 - val_mean_squared_error: 2.2825e-05\n",
            "Epoch 80/500\n",
            "2173/2183 [============================>.] - ETA: 0s - loss: 3.9422e-05 - mean_squared_error: 3.9422e-05\n",
            "Epoch 00080: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.9282e-05 - mean_squared_error: 3.9282e-05 - val_loss: 2.4393e-05 - val_mean_squared_error: 2.4393e-05\n",
            "Epoch 81/500\n",
            "2176/2183 [============================>.] - ETA: 0s - loss: 3.9306e-05 - mean_squared_error: 3.9306e-05\n",
            "Epoch 00081: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.9204e-05 - mean_squared_error: 3.9204e-05 - val_loss: 3.2948e-05 - val_mean_squared_error: 3.2948e-05\n",
            "Epoch 82/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 3.8836e-05 - mean_squared_error: 3.8836e-05\n",
            "Epoch 00082: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.8836e-05 - mean_squared_error: 3.8836e-05 - val_loss: 2.5337e-05 - val_mean_squared_error: 2.5337e-05\n",
            "Epoch 83/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 3.8183e-05 - mean_squared_error: 3.8183e-05\n",
            "Epoch 00083: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.8183e-05 - mean_squared_error: 3.8183e-05 - val_loss: 2.6875e-05 - val_mean_squared_error: 2.6875e-05\n",
            "Epoch 84/500\n",
            "2173/2183 [============================>.] - ETA: 0s - loss: 3.8676e-05 - mean_squared_error: 3.8676e-05\n",
            "Epoch 00084: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.8571e-05 - mean_squared_error: 3.8571e-05 - val_loss: 3.2218e-05 - val_mean_squared_error: 3.2218e-05\n",
            "Epoch 85/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 3.8053e-05 - mean_squared_error: 3.8053e-05\n",
            "Epoch 00085: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.8053e-05 - mean_squared_error: 3.8053e-05 - val_loss: 2.5971e-05 - val_mean_squared_error: 2.5971e-05\n",
            "Epoch 86/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 3.7566e-05 - mean_squared_error: 3.7566e-05\n",
            "Epoch 00086: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.7518e-05 - mean_squared_error: 3.7518e-05 - val_loss: 2.3949e-05 - val_mean_squared_error: 2.3949e-05\n",
            "Epoch 87/500\n",
            "2181/2183 [============================>.] - ETA: 0s - loss: 3.8246e-05 - mean_squared_error: 3.8246e-05\n",
            "Epoch 00087: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.8227e-05 - mean_squared_error: 3.8227e-05 - val_loss: 3.5650e-05 - val_mean_squared_error: 3.5650e-05\n",
            "Epoch 88/500\n",
            "2176/2183 [============================>.] - ETA: 0s - loss: 3.8116e-05 - mean_squared_error: 3.8116e-05\n",
            "Epoch 00088: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.8096e-05 - mean_squared_error: 3.8096e-05 - val_loss: 5.7012e-05 - val_mean_squared_error: 5.7012e-05\n",
            "Epoch 89/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 3.8136e-05 - mean_squared_error: 3.8136e-05\n",
            "Epoch 00089: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.8031e-05 - mean_squared_error: 3.8031e-05 - val_loss: 2.8321e-05 - val_mean_squared_error: 2.8321e-05\n",
            "Epoch 90/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 3.6730e-05 - mean_squared_error: 3.6730e-05\n",
            "Epoch 00090: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.6614e-05 - mean_squared_error: 3.6614e-05 - val_loss: 2.1601e-05 - val_mean_squared_error: 2.1601e-05\n",
            "Epoch 91/500\n",
            "2176/2183 [============================>.] - ETA: 0s - loss: 3.6482e-05 - mean_squared_error: 3.6482e-05\n",
            "Epoch 00091: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.6442e-05 - mean_squared_error: 3.6442e-05 - val_loss: 2.4646e-05 - val_mean_squared_error: 2.4646e-05\n",
            "Epoch 92/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 3.8575e-05 - mean_squared_error: 3.8575e-05\n",
            "Epoch 00092: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.8575e-05 - mean_squared_error: 3.8575e-05 - val_loss: 3.7119e-05 - val_mean_squared_error: 3.7119e-05\n",
            "Epoch 93/500\n",
            "2178/2183 [============================>.] - ETA: 0s - loss: 3.5523e-05 - mean_squared_error: 3.5523e-05\n",
            "Epoch 00093: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.5495e-05 - mean_squared_error: 3.5495e-05 - val_loss: 5.8689e-05 - val_mean_squared_error: 5.8689e-05\n",
            "Epoch 94/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 3.6399e-05 - mean_squared_error: 3.6399e-05\n",
            "Epoch 00094: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.6399e-05 - mean_squared_error: 3.6399e-05 - val_loss: 3.0018e-05 - val_mean_squared_error: 3.0018e-05\n",
            "Epoch 95/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 3.6497e-05 - mean_squared_error: 3.6497e-05\n",
            "Epoch 00095: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.6497e-05 - mean_squared_error: 3.6497e-05 - val_loss: 3.0723e-05 - val_mean_squared_error: 3.0723e-05\n",
            "Epoch 96/500\n",
            "2174/2183 [============================>.] - ETA: 0s - loss: 3.7502e-05 - mean_squared_error: 3.7502e-05\n",
            "Epoch 00096: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.7402e-05 - mean_squared_error: 3.7402e-05 - val_loss: 2.3704e-05 - val_mean_squared_error: 2.3704e-05\n",
            "Epoch 97/500\n",
            "2182/2183 [============================>.] - ETA: 0s - loss: 3.6608e-05 - mean_squared_error: 3.6608e-05\n",
            "Epoch 00097: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.6646e-05 - mean_squared_error: 3.6646e-05 - val_loss: 3.1802e-05 - val_mean_squared_error: 3.1802e-05\n",
            "Epoch 98/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 3.5978e-05 - mean_squared_error: 3.5978e-05\n",
            "Epoch 00098: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.5978e-05 - mean_squared_error: 3.5978e-05 - val_loss: 2.3659e-05 - val_mean_squared_error: 2.3659e-05\n",
            "Epoch 99/500\n",
            "2177/2183 [============================>.] - ETA: 0s - loss: 3.5992e-05 - mean_squared_error: 3.5992e-05\n",
            "Epoch 00099: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.5916e-05 - mean_squared_error: 3.5916e-05 - val_loss: 2.1211e-05 - val_mean_squared_error: 2.1211e-05\n",
            "Epoch 100/500\n",
            "2181/2183 [============================>.] - ETA: 0s - loss: 3.6826e-05 - mean_squared_error: 3.6826e-05\n",
            "Epoch 00100: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.6803e-05 - mean_squared_error: 3.6803e-05 - val_loss: 4.6611e-05 - val_mean_squared_error: 4.6611e-05\n",
            "Epoch 101/500\n",
            "2181/2183 [============================>.] - ETA: 0s - loss: 3.6899e-05 - mean_squared_error: 3.6899e-05\n",
            "Epoch 00101: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.6869e-05 - mean_squared_error: 3.6869e-05 - val_loss: 1.9777e-05 - val_mean_squared_error: 1.9777e-05\n",
            "Epoch 102/500\n",
            "2175/2183 [============================>.] - ETA: 0s - loss: 3.6352e-05 - mean_squared_error: 3.6352e-05\n",
            "Epoch 00102: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.6236e-05 - mean_squared_error: 3.6236e-05 - val_loss: 2.4851e-05 - val_mean_squared_error: 2.4851e-05\n",
            "Epoch 103/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 3.5225e-05 - mean_squared_error: 3.5225e-05\n",
            "Epoch 00103: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.5253e-05 - mean_squared_error: 3.5253e-05 - val_loss: 2.6715e-05 - val_mean_squared_error: 2.6715e-05\n",
            "Epoch 104/500\n",
            "2174/2183 [============================>.] - ETA: 0s - loss: 3.6937e-05 - mean_squared_error: 3.6937e-05\n",
            "Epoch 00104: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.6901e-05 - mean_squared_error: 3.6901e-05 - val_loss: 6.4028e-05 - val_mean_squared_error: 6.4028e-05\n",
            "Epoch 105/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 3.7636e-05 - mean_squared_error: 3.7636e-05\n",
            "Epoch 00105: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.7590e-05 - mean_squared_error: 3.7590e-05 - val_loss: 2.4515e-05 - val_mean_squared_error: 2.4515e-05\n",
            "Epoch 106/500\n",
            "2174/2183 [============================>.] - ETA: 0s - loss: 3.4609e-05 - mean_squared_error: 3.4609e-05\n",
            "Epoch 00106: val_loss improved from 0.00002 to 0.00002, saving model to ./model/106-0.0000.hdf5\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.4488e-05 - mean_squared_error: 3.4488e-05 - val_loss: 1.9047e-05 - val_mean_squared_error: 1.9047e-05\n",
            "Epoch 107/500\n",
            "2178/2183 [============================>.] - ETA: 0s - loss: 3.4088e-05 - mean_squared_error: 3.4088e-05\n",
            "Epoch 00107: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 13s 6ms/step - loss: 3.4112e-05 - mean_squared_error: 3.4112e-05 - val_loss: 3.6647e-05 - val_mean_squared_error: 3.6647e-05\n",
            "Epoch 108/500\n",
            "2173/2183 [============================>.] - ETA: 0s - loss: 3.4772e-05 - mean_squared_error: 3.4772e-05\n",
            "Epoch 00108: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.4639e-05 - mean_squared_error: 3.4639e-05 - val_loss: 2.3142e-05 - val_mean_squared_error: 2.3142e-05\n",
            "Epoch 109/500\n",
            "2179/2183 [============================>.] - ETA: 0s - loss: 3.5109e-05 - mean_squared_error: 3.5109e-05\n",
            "Epoch 00109: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.5112e-05 - mean_squared_error: 3.5112e-05 - val_loss: 8.9995e-05 - val_mean_squared_error: 8.9995e-05\n",
            "Epoch 110/500\n",
            "2182/2183 [============================>.] - ETA: 0s - loss: 3.4012e-05 - mean_squared_error: 3.4012e-05\n",
            "Epoch 00110: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.4007e-05 - mean_squared_error: 3.4007e-05 - val_loss: 2.1920e-05 - val_mean_squared_error: 2.1920e-05\n",
            "Epoch 111/500\n",
            "2181/2183 [============================>.] - ETA: 0s - loss: 3.5276e-05 - mean_squared_error: 3.5276e-05\n",
            "Epoch 00111: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.5317e-05 - mean_squared_error: 3.5317e-05 - val_loss: 2.5103e-05 - val_mean_squared_error: 2.5103e-05\n",
            "Epoch 112/500\n",
            "2183/2183 [==============================] - ETA: 0s - loss: 3.6866e-05 - mean_squared_error: 3.6866e-05\n",
            "Epoch 00112: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.6866e-05 - mean_squared_error: 3.6866e-05 - val_loss: 3.4054e-05 - val_mean_squared_error: 3.4054e-05\n",
            "Epoch 113/500\n",
            "2180/2183 [============================>.] - ETA: 0s - loss: 3.5364e-05 - mean_squared_error: 3.5364e-05\n",
            "Epoch 00113: val_loss did not improve from 0.00002\n",
            "2183/2183 [==============================] - 11s 5ms/step - loss: 3.5356e-05 - mean_squared_error: 3.5356e-05 - val_loss: 1.9913e-05 - val_mean_squared_error: 1.9913e-05\n",
            "Epoch 114/500\n",
            " 567/2183 [======>.......................] - ETA: 7s - loss: 2.6617e-05 - mean_squared_error: 2.6617e-05"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-9420461ec13d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m hist = model.fit(X_train_t, y_train, validation_split=0.2, epochs=500,\n\u001b[0;32m----> 6\u001b[0;31m           batch_size=20, verbose=1, callbacks=[checkpointer, early_stop])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwqgKNTI9ONI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b246616-ccbb-4e31-f918-3c5aa03f3600"
      },
      "source": [
        "# loss는 매 에포크 마다의 훈련 손실값\n",
        "# acc는 매 에포크 마다의 훈련 정확도\n",
        "# val_loss는 매 에포크 마다의 검증 손실값\n",
        "# val_acc는 매 에포크 마다의 검증 정확도\n",
        "# validation loss가 증가하기 시작한다면, 모델이 과적합이 되고 있다고 판단\n",
        "hist.history"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05,\n",
              "  2.2905309378984384e-05],\n",
              " 'loss': [8.870003512129188e-05,\n",
              "  8.145039464579895e-05,\n",
              "  7.885537343099713e-05,\n",
              "  7.841287879273295e-05,\n",
              "  7.37527952878736e-05,\n",
              "  7.376070425380021e-05,\n",
              "  6.915726407896727e-05,\n",
              "  7.026134699117392e-05,\n",
              "  6.685081461910158e-05,\n",
              "  6.562832277268171e-05,\n",
              "  6.696298805763945e-05,\n",
              "  6.475055124610662e-05,\n",
              "  6.208812555996701e-05,\n",
              "  6.424004095606506e-05,\n",
              "  6.256794586079195e-05,\n",
              "  6.0246868088142946e-05,\n",
              "  5.8187288232147694e-05,\n",
              "  5.872535621165298e-05,\n",
              "  5.786276233266108e-05,\n",
              "  5.585514736594632e-05,\n",
              "  5.743511064792983e-05,\n",
              "  5.7243418268626556e-05,\n",
              "  5.602559758699499e-05,\n",
              "  5.536878597922623e-05,\n",
              "  5.2453156968113035e-05,\n",
              "  5.2566818339983e-05,\n",
              "  5.354822496883571e-05,\n",
              "  5.17341322847642e-05,\n",
              "  5.462778790388256e-05,\n",
              "  5.1140599680365995e-05,\n",
              "  5.097595931147225e-05,\n",
              "  4.9564976507099345e-05,\n",
              "  5.039003735873848e-05,\n",
              "  4.837382221012376e-05,\n",
              "  4.7838395403232425e-05,\n",
              "  4.6318415115820244e-05,\n",
              "  4.7925783292157575e-05,\n",
              "  4.9419286369811743e-05,\n",
              "  4.7297897253884e-05,\n",
              "  4.7303212340921164e-05,\n",
              "  4.6931105316616595e-05,\n",
              "  4.672074646805413e-05,\n",
              "  4.5024346036370844e-05,\n",
              "  4.655114753404632e-05,\n",
              "  4.553686085273512e-05,\n",
              "  4.387049193610437e-05,\n",
              "  4.508238271228038e-05,\n",
              "  4.412559064803645e-05,\n",
              "  4.313660247134976e-05,\n",
              "  4.3364161683712155e-05,\n",
              "  4.241044371156022e-05,\n",
              "  4.131438254262321e-05,\n",
              "  4.287729461793788e-05,\n",
              "  4.062599327880889e-05,\n",
              "  4.0628714486956596e-05,\n",
              "  4.1849696572171524e-05,\n",
              "  4.0666607674211264e-05,\n",
              "  4.081297083757818e-05,\n",
              "  4.055879981024191e-05,\n",
              "  3.9912189095048234e-05,\n",
              "  4.084972897544503e-05,\n",
              "  3.9834143535699695e-05,\n",
              "  4.219970651320182e-05,\n",
              "  3.937447036150843e-05,\n",
              "  3.9926260797074065e-05,\n",
              "  3.905170888174325e-05,\n",
              "  4.0178339986596256e-05,\n",
              "  3.7871443055337295e-05,\n",
              "  3.879088399116881e-05,\n",
              "  3.84915474569425e-05,\n",
              "  3.63950603059493e-05,\n",
              "  3.8579517422476783e-05,\n",
              "  3.787168679991737e-05,\n",
              "  3.94919807149563e-05,\n",
              "  3.6959074350306764e-05,\n",
              "  3.562500569387339e-05,\n",
              "  3.8314297853503376e-05,\n",
              "  3.707781434059143e-05,\n",
              "  3.6727305996464565e-05,\n",
              "  3.7064211937831715e-05,\n",
              "  3.707335054059513e-05,\n",
              "  3.6178047594148666e-05,\n",
              "  3.721008397405967e-05,\n",
              "  3.728071533259936e-05,\n",
              "  3.6390953027876094e-05,\n",
              "  3.6031742638442665e-05],\n",
              " 'val_accuracy': [0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205,\n",
              "  0.0010077874176204205],\n",
              " 'val_loss': [5.2536794100888073e-05,\n",
              "  0.00011792675650212914,\n",
              "  9.21765313250944e-05,\n",
              "  4.1839837649604306e-05,\n",
              "  3.2185875170398504e-05,\n",
              "  3.280584132880904e-05,\n",
              "  4.599065869115293e-05,\n",
              "  3.996611121692695e-05,\n",
              "  4.076934783370234e-05,\n",
              "  4.5661490730708465e-05,\n",
              "  3.391342761460692e-05,\n",
              "  2.8107737307436764e-05,\n",
              "  2.8849543014075607e-05,\n",
              "  2.75897891697241e-05,\n",
              "  2.5924211513483897e-05,\n",
              "  3.8789756217738613e-05,\n",
              "  4.0657672798261046e-05,\n",
              "  9.578225581208244e-05,\n",
              "  2.7048439733334817e-05,\n",
              "  3.868347994284704e-05,\n",
              "  2.594717989268247e-05,\n",
              "  2.4827464585541748e-05,\n",
              "  4.113679096917622e-05,\n",
              "  3.283789556007832e-05,\n",
              "  3.8315651181619614e-05,\n",
              "  2.8195503546157852e-05,\n",
              "  9.876964031718671e-05,\n",
              "  2.7850572223542258e-05,\n",
              "  5.4699699830962345e-05,\n",
              "  2.2359447029884905e-05,\n",
              "  2.2784428438171744e-05,\n",
              "  0.0002835507912095636,\n",
              "  2.042633423116058e-05,\n",
              "  2.1937374185654335e-05,\n",
              "  2.7640655389404856e-05,\n",
              "  2.7802494514617138e-05,\n",
              "  4.602692570188083e-05,\n",
              "  1.9934926967835054e-05,\n",
              "  0.0001167043301393278,\n",
              "  2.0905161363771185e-05,\n",
              "  3.4305223380215466e-05,\n",
              "  7.503571396227926e-05,\n",
              "  2.337109253858216e-05,\n",
              "  3.0939914722694084e-05,\n",
              "  3.7656925996998325e-05,\n",
              "  2.2289397747954354e-05,\n",
              "  1.9571956727304496e-05,\n",
              "  2.0640725779230706e-05,\n",
              "  0.00010289303463650867,\n",
              "  3.6312056181486696e-05,\n",
              "  2.8688738893833943e-05,\n",
              "  2.1898636987316422e-05,\n",
              "  2.969160777865909e-05,\n",
              "  3.585022204788402e-05,\n",
              "  7.173807534854859e-05,\n",
              "  3.456570993876085e-05,\n",
              "  2.3795877496013418e-05,\n",
              "  2.60811884800205e-05,\n",
              "  6.493299588328227e-05,\n",
              "  3.0213761419872753e-05,\n",
              "  3.09320748783648e-05,\n",
              "  2.4992743419716135e-05,\n",
              "  2.0351810235297307e-05,\n",
              "  2.3118640456232242e-05,\n",
              "  1.9953160517616197e-05,\n",
              "  2.2100881324149668e-05,\n",
              "  3.460592415649444e-05,\n",
              "  0.00011395695764804259,\n",
              "  4.7124813136179e-05,\n",
              "  3.8736754504498094e-05,\n",
              "  0.00013746229524258524,\n",
              "  2.1855812519788742e-05,\n",
              "  6.117287557572126e-05,\n",
              "  3.040233059437014e-05,\n",
              "  2.3452394088963047e-05,\n",
              "  2.1894284145673737e-05,\n",
              "  2.184629011026118e-05,\n",
              "  2.0361929273349233e-05,\n",
              "  2.2854635972180404e-05,\n",
              "  7.802778418408707e-05,\n",
              "  2.487839992681984e-05,\n",
              "  6.211863365024328e-05,\n",
              "  2.5020535758812912e-05,\n",
              "  2.4268289052997716e-05,\n",
              "  2.7767619030782953e-05,\n",
              "  2.1473862943821587e-05]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "048Qk7xS9uki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "2362ad96-eb06-48cd-8b45-f55f57856c4c"
      },
      "source": [
        "y_vloss = hist.history['val_loss']   # 테스트셋 오차\n",
        "#print(len(y_vloss))   # shape함수는 리스트에 적용안됨\n",
        "\n",
        "# 학습셋 정확도\n",
        "y_acc = hist.history['accuracy']\n",
        "\n",
        "# 테스트셋 정확도\n",
        "y_val_accuracy = hist.history['val_accuracy']\n",
        "x_len = np.arange(len(y_acc))\n",
        "\n",
        "#학습셋 정확도 라인\n",
        "plt.plot(x_len, y_acc, 'o', c='blue', markersize=3, label = 'Trainset_accuarcy')\n",
        "\n",
        "#테스트셋 오차 라인\n",
        "plt.plot(x_len, y_vloss, 'o', c='red', markersize=3, label = 'Testset_loss')\n",
        "\n",
        "plt.legend(loc='best')   #location  right, left, upper rigtht 등등 \n",
        "plt.grid()   # 격자 \n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('score')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 테스트 정확도 출력\n",
        "print(' Accuracy: %.4f' % y_val_accuracy[-1])  \n",
        "#제일 마지막 정확도를 가져오고 싶어서 인덱싱 -1번 "
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z4PUTWQkygH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "a975c6da-e451-4e96-fe88-23611c1ddebd"
      },
      "source": [
        "train_sc_df.describe()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WL</th>\n",
              "      <th>shift_1</th>\n",
              "      <th>shift_2</th>\n",
              "      <th>shift_3</th>\n",
              "      <th>shift_4</th>\n",
              "      <th>shift_5</th>\n",
              "      <th>shift_6</th>\n",
              "      <th>shift_7</th>\n",
              "      <th>shift_8</th>\n",
              "      <th>shift_9</th>\n",
              "      <th>shift_10</th>\n",
              "      <th>shift_11</th>\n",
              "      <th>shift_12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>54585.000000</td>\n",
              "      <td>54584.000000</td>\n",
              "      <td>54583.000000</td>\n",
              "      <td>54582.000000</td>\n",
              "      <td>54581.000000</td>\n",
              "      <td>54580.000000</td>\n",
              "      <td>54579.000000</td>\n",
              "      <td>54578.000000</td>\n",
              "      <td>54577.000000</td>\n",
              "      <td>54576.000000</td>\n",
              "      <td>54575.000000</td>\n",
              "      <td>54574.000000</td>\n",
              "      <td>54573.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.131481</td>\n",
              "      <td>0.131476</td>\n",
              "      <td>0.131472</td>\n",
              "      <td>0.131467</td>\n",
              "      <td>0.131463</td>\n",
              "      <td>0.131458</td>\n",
              "      <td>0.131453</td>\n",
              "      <td>0.131449</td>\n",
              "      <td>0.131444</td>\n",
              "      <td>0.131440</td>\n",
              "      <td>0.131435</td>\n",
              "      <td>0.131430</td>\n",
              "      <td>0.131426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.097404</td>\n",
              "      <td>0.097399</td>\n",
              "      <td>0.097394</td>\n",
              "      <td>0.097388</td>\n",
              "      <td>0.097383</td>\n",
              "      <td>0.097378</td>\n",
              "      <td>0.097373</td>\n",
              "      <td>0.097368</td>\n",
              "      <td>0.097363</td>\n",
              "      <td>0.097358</td>\n",
              "      <td>0.097353</td>\n",
              "      <td>0.097348</td>\n",
              "      <td>0.097343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "      <td>0.061758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "      <td>0.159145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 WL       shift_1  ...      shift_11      shift_12\n",
              "count  54585.000000  54584.000000  ...  54574.000000  54573.000000\n",
              "mean       0.131481      0.131476  ...      0.131430      0.131426\n",
              "std        0.097404      0.097399  ...      0.097348      0.097343\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%        0.061758      0.061758  ...      0.061758      0.061758\n",
              "50%        0.121140      0.121140  ...      0.121140      0.121140\n",
              "75%        0.159145      0.159145  ...      0.159145      0.159145\n",
              "max        1.000000      1.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi1_WXcdmDIo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "fdfbc525-0f75-49a3-a14f-f4fa06b6b889"
      },
      "source": [
        "test_sc_df.describe()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WL</th>\n",
              "      <th>shift_1</th>\n",
              "      <th>shift_2</th>\n",
              "      <th>shift_3</th>\n",
              "      <th>shift_4</th>\n",
              "      <th>shift_5</th>\n",
              "      <th>shift_6</th>\n",
              "      <th>shift_7</th>\n",
              "      <th>shift_8</th>\n",
              "      <th>shift_9</th>\n",
              "      <th>shift_10</th>\n",
              "      <th>shift_11</th>\n",
              "      <th>shift_12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>56586.000000</td>\n",
              "      <td>56585.000000</td>\n",
              "      <td>56584.000000</td>\n",
              "      <td>56583.000000</td>\n",
              "      <td>56582.000000</td>\n",
              "      <td>56581.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56579.000000</td>\n",
              "      <td>56578.000000</td>\n",
              "      <td>56577.000000</td>\n",
              "      <td>56576.000000</td>\n",
              "      <td>56575.000000</td>\n",
              "      <td>56574.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.199371</td>\n",
              "      <td>0.199369</td>\n",
              "      <td>0.199367</td>\n",
              "      <td>0.199366</td>\n",
              "      <td>0.199364</td>\n",
              "      <td>0.199362</td>\n",
              "      <td>0.199361</td>\n",
              "      <td>0.199359</td>\n",
              "      <td>0.199358</td>\n",
              "      <td>0.199356</td>\n",
              "      <td>0.199354</td>\n",
              "      <td>0.199353</td>\n",
              "      <td>0.199351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.147557</td>\n",
              "      <td>0.147558</td>\n",
              "      <td>0.147559</td>\n",
              "      <td>0.147560</td>\n",
              "      <td>0.147561</td>\n",
              "      <td>0.147561</td>\n",
              "      <td>0.147562</td>\n",
              "      <td>0.147563</td>\n",
              "      <td>0.147564</td>\n",
              "      <td>0.147565</td>\n",
              "      <td>0.147565</td>\n",
              "      <td>0.147566</td>\n",
              "      <td>0.147567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "      <td>-0.076010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.059382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "      <td>0.121140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "      <td>0.351544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "      <td>1.057007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 WL       shift_1  ...      shift_11      shift_12\n",
              "count  56586.000000  56585.000000  ...  56575.000000  56574.000000\n",
              "mean       0.199371      0.199369  ...      0.199353      0.199351\n",
              "std        0.147557      0.147558  ...      0.147566      0.147567\n",
              "min       -0.076010     -0.076010  ...     -0.076010     -0.076010\n",
              "25%        0.059382      0.059382  ...      0.059382      0.059382\n",
              "50%        0.121140      0.121140  ...      0.121140      0.121140\n",
              "75%        0.351544      0.351544  ...      0.351544      0.351544\n",
              "max        1.057007      1.057007  ...      1.057007      1.057007\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24U1xkWvm1EW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9f210799-da56-48cc-b309-3437e7341745"
      },
      "source": [
        "# evaluate 메소드 활용: compile에서 사용했던 metric, mse값 확인\n",
        "score = model.evaluate(X_test_t, y_test, batch_size=20)\n",
        "print(score)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "546/546 [==============================] - 1s 2ms/step - loss: 4.7073e-05 - mean_squared_error: 4.7073e-05\n",
            "[4.707257539848797e-05, 4.707257539848797e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpqq7vKqmMM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "59e40e38-c0a2-469c-d277-17c406d0dc03"
      },
      "source": [
        "# 예측 결과 시각화하여 확인\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 원래 값과 예측 값이 일치하면 직선에 가깝게 분포가 되는데 결과가 나쁘지 않다\n",
        "y_pred = model.predict(X_test_t, batch_size=32)\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"WL Index: $Y_i$\")\n",
        "plt.ylabel(\"Predicted WL Index: $\\hat{Y}_i$\")\n",
        "plt.title(\"WL vs Predicted WL Index: $Y_i$ vs $\\hat{Y}_i$\")"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input Tensor(\"lstm_input:0\", shape=(None, 1, 1), dtype=float32), but it was called on an input with incompatible shape (None, 12, 1).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'WL vs Predicted WL Index: $Y_i$ vs $\\\\hat{Y}_i$')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn4H1hmumPdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "de1fb05b-f544-46c8-c452-8eb4ffde03bd"
      },
      "source": [
        "# test 값과 예측 값 시각화\n",
        "plt.plot(y_test, 'bo-', label='실제')\n",
        "plt.plot(y_pred, 'ro-', label='예측')\n",
        "plt.legend()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe2d96c7518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51228 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50696 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52769 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51228 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50696 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52769 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jodixQb4uER9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}